# Improving Various Segmentation model <br> by Augmentation using StableDiffusionXL <br> with Null-text Inversion + Prompt-to-Prompt

<details>
<summary style="font-size:20px; font-weight:bold;">mmSegmentationì˜ ê°„ë‹¨í•œ ì„¤ëª…</summary>
<div markdown="1">

### | êµ¬ì¡°
ê¸°ë³¸ì ìœ¼ë¡œ train.pyë¥¼ ì‚´í´ë³´ë©´, configs ë””ë ‰í† ë¦¬ ë‚´ì˜ config íŒŒì¼ í•˜ë‚˜ë§Œì„ ê°€ì§€ê³  í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ì´ configíŒŒì¼ì•ˆì— ë°ì´í„°ì…‹, ëª¨ë¸ ë“± ëª¨ë“  ë‚´ìš©ì´ ë“¤ì–´ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ ì½”ë“œë¥¼ ë³´ë©´ì„œ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤.
#### * Config íŒŒì¼
```python
# _base__ ë¦¬ìŠ¤íŠ¸ë¥¼ í†µí•´ 
_base_ = [
    '../_base_/models/deeplabv3_r50-d8.py', #ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í• ê±´ì§€,
    '../_base_/datasets/wta_512.py', #ì–´ë–¤ ë°ì´í„°ì…‹ ì˜µì…˜ì„ ì‚¬ìš©í• ê±´ì§€
    '../_base_/default_runtime.py', #(ì´ê±´ ê¸°ë³¸ ìŠ¤ì¼€ì¤„ ì˜µì…˜ì…ë‹ˆë‹¤.)
    '../_base_/schedules/schedule_40k.py' #ì–¼ë§ˆë‚˜ ë°˜ë³µí• ì§€ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
]
# ì•„ë˜ì— ì‘ì„±ëœ ê²ƒì€ ê¸°ì¡´ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ë³€ê²½í•˜ê³  ì‹¶ì„ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ê¸°ì¡´ ëª¨ë¸ì˜ ì½”ë“œì— ì•„ë˜ì½”ë“œê°€ ì˜¤ë²„ë¼ì´ë”©ë©ë‹ˆë‹¤.
# ë”°ë¼ì„œ ì´ìš©í•˜ê³  ì‹¶ì€ ë°ì´í„°ì…‹ì— ë§ë„ë¡, crop_size, num_classesë¥¼ ë³€ê²½í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
crop_size = (256, 256)
data_preprocessor = dict(size=crop_size)
model = dict(
    data_preprocessor=data_preprocessor,
    decode_head=dict(num_classes=3),
    auxiliary_head=dict(num_classes=3))

```
#### * Dataset config íŒŒì¼
configs/\_base_/datasets ë””ë ‰í† ë¦¬ ë‚´ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.  
í•´ë‹¹ config íŒŒì¼ì€ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì˜µì…˜ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.  
```python
dataset_type = 'WTADataset' #ì–´ë–¤ íƒ€ì…ì˜ ë°ì´í„°ì…‹ì¸ì§€
data_root = './data/wta_512/' #ë°ì´í„°ì˜ ìœ„ì¹˜ëŠ” ì–´ë””ì¸ì§€
...
data_prefix=dict(
            img_path='img_dir/train', seg_map_path='ann_dir/train') #wta512/img_dir: ì´ë¯¸ì§€ê°€ ë“¤ì–´ìˆìŒ. wta512/ann_dirì—ëŠ” ë ˆì´ë¸”ì´ ë“¤ì–´ìˆìŒì„ ì•Œë ¤ì¤Œ.
...
val_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU']) #í‰ê°€ ë°©ë²•ì„ ì •í•¨.
test_evaluator = val_evaluator
```

#### *schedule config íŒŒì¼
configs/\_base_/schedules ë””ë ‰í† ë¦¬ ë‚´ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.
í•´ë‹¹ config íŒŒì¼ì€ í•™ìŠµ ìŠ¤ì¼€ì¤„ëŸ¬ì— ëŒ€í•œ ì˜µì…˜ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.
```python
param_scheduler = [
    dict(
        type='PolyLR',
        eta_min=1e-4,
        power=0.9,
        begin=0,
        end=40000,
        by_epoch=False)
]
```
ì£¼ë¡œ lr ê°ì†Œìœ¨ì„ ë³€í™”ì‹œí‚¬ ë•Œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. end 40000ì„ í•˜ê²Œ ë˜ë©´, 40k ì— ë§Ÿì¤˜ ë§ˆì§€ë§‰ì´ lrì´ 0ì´ ë˜ë„ë¡ ë–¨ì–´ì§‘ë‹ˆë‹¤.
ì´ ê°’ì„ í‚¤ìš°ê²Œ ë˜ë©´, ëª¨ë“  iterationì„ ëŒì•˜ì„ ë•Œ ìµœì¢… lrì˜ í¬ê¸°ê°€ ì»¤ì§€ê²Œ ë©ë‹ˆë‹¤.

### | ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ë§Œë“¤ê¸°
mmseg/datasets ë””ë ‰í† ë¦¬ ë‚´ì— ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹´ì€ í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ì–´ì£¼ì–´ì•¼í•©ë‹ˆë‹¤.  
```python
from mmseg.registry import DATASETS
from .basesegdataset import BaseSegDataset


@DATASETS.register_module() #ì¤‘ìš”
class WTADataset(BaseSegDataset):
    METAINFO = dict(
        classes=('defect', 'attached', 'broken'), # ì‚¬ìš©í•˜ê³  ì‹¶ì€ ë°ì´í„°ì˜ ë ˆì´ë¸”ì´ë¦„
        palette=[[0, 0, 0], [255, 0, 0], [0, 255, 0]]) # ê° ë ˆì´ë¸”ì— ëŒ€ì‘ë˜ëŠ” ìƒ‰ìƒ

    def __init__(self,
                 img_suffix='.png',
                 seg_map_suffix='.png',
                 reduce_zero_label=True,
                 **kwargs) -> None:
        super().__init__(
            img_suffix=img_suffix,
            seg_map_suffix=seg_map_suffix,
            reduce_zero_label=False,
            **kwargs)
```  
ê·¸ë¦¬ê³  ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì´ í•˜ë‚˜ ë‚¨ì•˜ìŠµë‹ˆë‹¤.
```
mmseg/datasets/__init__.py
```
ì— í•´ë‹¹ í´ë˜ìŠ¤ê°€ ìˆìŒì„ ì•Œë ¤ì¤˜ì•¼í•©ë‹ˆë‹¤.  
**__init__.py**ë¥¼ ì—´ê³  
```python
from .wta import WTADataset #ìœ„ì—ì„œ ì‘ì„±í•œ í´ë˜ìŠ¤ ëª¨ë“ˆì„ import
__all__ = [..., 'WTADataset'] #í´ë˜ìŠ¤ ì´ë¦„ì„ ì´ë ‡ê²Œ __all__ì— ì¶”ê°€í•´ì¤ë‹ˆë‹¤.
```
ê·¸ë¦¬ê³  ìœ„ì—ì„œ ì„œìˆ í•œ dataset_config íŒŒì¼ì„ ì‘ì„±í•œë’¤, configíŒŒì¼ì˜ _base_ ë¦¬ìŠ¤íŠ¸ ë‚´ì— ì´ë¥¼ ì¶”ê°€í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!  
ë§Œì•½ ìƒˆë¡œ ì¶”ê°€í•œ ë°ì´í„°ì…‹ ëª¨ë“ˆì´ ì—†ë‹¤ê³ í•˜ëŠ” ì—ëŸ¬ê°€ ë‚˜ê²Œë˜ë©´, recompileê³¼ì •ì´ ì´ ì—ëŸ¬ë¥¼ í•´ê²°í•´ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
```bash
pip install -v -e . # mmsegmentation ë””ë ‰í† ë¦¬ ë‚´ì—ì„œ ì‹¤í–‰
```
ì—ëŸ¬ê°€ í•´ê²°ë  ê²ƒì…ë‹ˆë‹¤!

### | ìƒˆë¡œìš´ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ë²• & í•™ìŠµ ë°©ë²•
ğŸ”¥ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµì„ í•˜ê³  ì‹¶ì€ ê²½ìš° ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¥¼ ë”°ë¼ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.

1. data ì— ê¸°ì¡´ ë°ì´í„°ì…‹ê³¼ ë™ì¼í•˜ê²Œ ë‚´ë¶€ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ë”°ë¥´ë˜, ë‹¤ìŒê³¼ ê°™ì´ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.
* ann_dir/train : ë ˆì´ë¸”(rgbê°’ ì•„ë‹ˆê³ , 0,1,2ë¡œ ëœ ê°’)
* img_dir/train : ë ˆì´ë¸”ì— ëŒ€ì‘ë˜ëŠ” ì´ë¦„ì„ ê°€ì§€ëŠ” ì›ë³¸ ì´ë¯¸ì§€  

2. configs/\_base_/datasets ë””ë ‰í† ë¦¬ ë‚´ì˜   
**[ë°ì´í„°ì…‹ ì´ë¦„].py** ìœ¼ë¡œ config íŒŒì¼ì„ ë§Œë“¤ì–´ì•¼í•©ë‹ˆë‹¤. ë§Œë“œëŠ” ë°©ë²•ì€ 'Dataset config íŒŒì¼' íŒŒíŠ¸ë¥¼ ì°¸ê³ í•˜ë©´ ë©ë‹ˆë‹¤.

ê·¸ëŸ¼ ì´ì œ ë°ì´í„°ì…‹ ì¤€ë¹„ëŠ” ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ í•™ìŠµìš© py íŒŒì¼ì„ config/ ë””ë ‰í† ë¦¬ ë‚´ì— í•™ìŠµìš© py íŒŒì¼ì„ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.

3. config ë””ë ‰í† ë¦¬ ë‚´ë¶€ì—ëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ëª¨ë¸ë“¤ì„ í•™ìŠµì‹œí‚¤ê¸°ìœ„í•œ py íŒŒì¼ì´ [ê° ëª¨ë¸ëª…]/ ë””ë ‰í† ë¦¬ ë‚´ì— ìœ„ì¹˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´ deeplabv3plusì˜ í•™ìŠµìš© pyëŠ” config/deeplabv3plus/ ë‚´ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.
```python
#ì˜ˆì‹œ py
_base_ = ['../_base_/models/deeplabv3plus_r50-d8.py', #ì‚¬ìš©í•  ëª¨ë¸ì…ë‹ˆë‹¤.
          '../_base_/datasets/final_relabeled_ori_aug_only_junhyung_re_val_re_test.py', #ì•ì„œ 2.ì—ì„œ ë§Œë“¤ì—ˆë˜ ë°ì´í„°ì…‹ìš© pyíŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.
          '../_base_/default_runtime.py', #ì´ê±´ ê±´ë“¤ì´ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
    '../_base_/schedules/schedule_40k_lr160k.py' #'schedule config' íŒŒì¼ íŒŒíŠ¸ì—ì„œ ì„¤ëª…í•œ schedule íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤.
]
crop_size = (512, 512)
data_preprocessor = dict(size=crop_size)
model = dict(
    data_preprocessor=data_preprocessor,
    decode_head=dict(num_classes=3), #í˜„ì¬ ì €í¬ì˜ ë°ì´í„°ì…‹ì˜ ë ˆì´ë¸” ë‚´ í´ë˜ìŠ¤ê°€ 3ê°œì´ë¯€ë¡œ 3ì„ ì…ë ¥í•´ì•¼í•©ë‹ˆë‹¤.
    auxiliary_head=dict(num_classes=3)) #í˜„ì¬ ì €í¬ì˜ ë°ì´í„°ì…‹ì˜ ë ˆì´ë¸” ë‚´ í´ë˜ìŠ¤ê°€ 3ê°œì´ë¯€ë¡œ 3ì„ ì…ë ¥í•´ì•¼í•©ë‹ˆë‹¤.
```

ê·¸ëŸ¼ ì´ì œ í•™ìŠµìš© pyê°€ ë§Œë“¤ì–´ì¡Œìœ¼ë‹ˆ ì´ê±¸ ê°€ì§€ê³  runì„ í•´ë´…ì‹œë‹¤.

4. ì—¬ëŸ¬ê°œì˜ ëª¨ë¸ì„ í•œë²ˆì— í•™ìŠµí•˜ê¸° ìœ„í•´(ìˆœì°¨ì ìœ¼ë¡œ) bash/run_main.sh ì‰˜ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤. ì‚¬ìš©ë°©ë²•ì€ ë§¨ ìœ„ì˜ run_main.shì˜ ì„¤ëª…ì„ ì°¸ê³ í•´ì£¼ì„¸ìš”. 3.ì—ì„œ ë§Œë“  í•™ìŠµìš© pyíŒŒì¼ì˜ ê²½ë¡œë¥¼ group1, group2ì— ì•„ë¬´ê³³ì—ë‚˜ ì¨ì£¼ë©´ë©ë‹ˆë‹¤. group1, 2ë¡œ ë‚˜ëˆ„ê²Œ ëœ ê²ƒì€ ì²˜ìŒì— origin, augmentationì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê³ ì ë‚˜ëˆ„ê²Œ ëœ ê²ƒì´ ê³„ê¸°ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.
ê·¸ëŸ¼ ì´ì œ work_dirs ë””ë ‰í† ë¦¬ì— í•™ìŠµëœ ê²°ê³¼ì™€ ê°€ì¤‘ì¹˜ íŒŒì¼, test ê²°ê³¼ê°€ ì €ì¥ë˜ê²Œ ë©ë‹ˆë‹¤.

ë§ë¶™ì´ëŠ” ë§>
* í˜„ì¬ ì‚¬ìš©ì¤‘ì¸ ë°ì´í„°ì…‹ì€   
```data/final_relabeled_ori_aug_only_junhyung_label_re_val_re_test```  
-> ```configs/\_base_/datasets/final_relabeled_ori_aug_only_junhyung_re_val_re_test.py```
ì…ë‹ˆë‹¤. ì´ëŠ” í•œëª…ì´ ìˆ˜í–‰í•œ ë ˆì´ë¸”ë§ìœ¼ë¡œ ì‹¤í—˜ì„ ì§„í–‰í–ˆì„ ë•Œ ë” ì¢‹ì€ ê²°ê³¼ê°€ ë‚˜ì˜¨ ì´í›„ë¡œ ì­‰ ì‚¬ìš©í•˜ê³  ìˆëŠ” ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.  


* only_junhyung ì´ ë¶™ì€ í•™ìŠµìš© pyëŠ” ìœ„ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.  
* lr40k, lr160k ê°€ ë¶™ì€ í•™ìŠµìš© pyëŠ” lr scheduler ì¤‘ ê°ê° end=40000, end=160000 ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.

</div>
</details>

<details>
<summary style="font-size:20px;font-weight:bold;">í•™ìŠµ ë° ì¶”ë¡  ë°©ë²•</summary>
<div markdown="1">

**bash/run_main.sh** ë¥¼ ì´ìš©í•´ ì—¬ëŸ¬ê°œì˜ ëª¨ë¸ì„ í•œë²ˆì— í•™ìŠµ ë° ì¶”ë¡ ì‹œì¼œ ê²°ê³¼ë¥¼ ë½‘ì•„ë‚¼ ìˆ˜ ìˆë‹¤.  
ë‹¤ìŒì€ run_main.shë¥¼ ì´ìš©í•˜ê¸° ìœ„í•´ ì„¤ì •í•´ì•¼í•˜ëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤.
``` sh
#work_dirs ë‚´ì˜ ì €ì¥ë˜ëŠ” ë””ë ‰í† ë¦¬ì˜ ì´ë¦„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë¡œì íŠ¸ ë³„ë¡œ ê²°ê³¼ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

read -p "Enter Project Name : " PROJECT_NAME #work_dirs ë‚´ì˜ ì €ì¥ë˜ëŠ” ë””ë ‰í† ë¦¬ì˜ ì´ë¦„ì…ë‹ˆë‹¤.
if [ "$PROJECT_NAME" == "" ]; then
    echo "Empty name is not acceptable."
    exit 1
fi
CUDA_VISIBLE_DEVICES=0 
read -p "Enter Gpu Count : " GPU_COUNT #GPUê°œìˆ˜ ì…ë ¥
if (($GPU_COUNT <= 0)); then
    echo "0 or Negative number of Gpu is not acceptable."
    exit 1
fi

#ì‹œë„í•´ë³¼ í•™ìŠµìš© py ì„ íƒ - configs ë””ë ‰í† ë¦¬ ë‚´ì˜ pyíŒŒì¼ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ì´ë¦„ë„ í•¨ê»˜ ì¨ì£¼ì–´ì•¼í•©ë‹ˆë‹¤.
# ì˜ˆì‹œ) configs/deeplabv3/deeplabv3_r50-d8_4xb4-40k_wta-256x256 ì¸ ê²½ìš°, 
# => deeplabv3/deeplabv3_r50-d8_4xb4-40k_wta-256x256

TEST_CANDI=( 
    deeplabv3/deeplabv3_r50-d8_4xb4-40k_wta_aug-256x256\ 
    bisenetv1/bisenetv1_r18-d32_4xb4-40k_wta_aug-256x256\
    fastfcn/fastfcn_r50-d32_jpu_psp_4xb4-40k_wta_aug-256x256
)

#ì „ë°˜ì ì¸ configë¥¼ ëª¨ë‘ ë‹´ê³ ìˆëŠ” configsíŒŒì¼ì˜ ìœ„ì¹˜
MODEL_CONFIG_PATH=./configs

#ê²°ê³¼ê°€ ì €ì¥ë  ë””ë ‰í† ë¦¬ë¥¼ ì…ë ¥
WORK_DIR=./work_dirs

#í•™ìŠµì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆì„ ë•Œ, 3ê°€ì§€ metricì˜ í‰ê· ì„ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§€ëŠ” ê°€ì¤‘ì¹˜ë¥¼ ì„ íƒí•´ testë¥¼ ì§„í–‰í•˜ê¸° ìœ„í•´
#best ê°€ì¤‘ì¹˜ë¥¼ ì°¾ëŠ” íŒŒì¼(find_best.py)ì˜ ìœ„ì¹˜ì…ë‹ˆë‹¤.
FIND_BEST_DIR=./bash
```
**íŒŒì¼ ì €ì¥ êµ¬ì¡°**
```
./workdirs/[Project Name]
                â”œâ”€â”€ exp
                    â”œâ”€â”€ [modelë””ë ‰í† ë¦¬/modelëª…]
                    â”‚           [test]
                    â”‚              â”œâ”€â”€ [test image ê²°ê³¼]
                    â”‚              â”œâ”€â”€ test_log.txt
                    â”‚           [train]
                    â”‚              â”œâ”€â”€â”€â”€â”€â”€â”€ [ì‹¤í–‰ì‹œê°„ìœ¼ë¡œ ì •ì˜ëœ ë””ë ‰í† ë¦¬]
                    â”‚              â”‚                    â”œâ”€â”€ vis_data
                    â”‚              â”‚                    â”‚       â”œâ”€â”€ [ì‹¤í–‰ì‹œê°„ìœ¼ë¡œ ì •ì˜ëœ ì´ë¦„].json
                    â”‚              â”‚                    â”‚       â”œâ”€â”€ config.py
                    â”‚              â”‚                    â”‚       â””â”€â”€ scalars.json
                    â”‚              â”‚                    â””â”€â”€ [ì‹¤í–‰ì‹œê°„ìœ¼ë¡œ ì •ì˜ëœ ì´ë¦„].log
                    â”‚              â””â”€â”€â”€â”€â”€â”€â”€ ckpt (ê°€ì¤‘ì¹˜ íŒŒì¼)
                    â”‚
                    â”‚
                    â”œâ”€â”€ [modelë””ë ‰í† ë¦¬/modelëª…]         
                    .                                
                    .                                
                    .

```
### â—ï¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ” test/test_log.txt ì˜ ë§¨ ì•„ë˜ì— ìœ„ì¹˜í•©ë‹ˆë‹¤! ê·¸ ê°’ìœ¼ë¡œ ì„±ëŠ¥ ë¹„êµë¥¼ í•©ë‹ˆë‹¤! â—ï¸

</div>
</details>

## Before we start...
### Setup the environment
```
conda env create --file environment.yaml
```
### Training for final result
```
bash bash/run_main.sh
```
### Remarks
There are no pretrained weight file(.pth). You must find the weight file from the internet to train some models.

## Data and Defect Description

**Dataset Composition**: Industrial blade defect image data

**Defect Types**:
<p align="center">
    <img src="./readme_img/attached_broken.png" width=500>
</p>


- **Attached Defects**
Appear as golden speckle patterns occurring individually or in clusters

- **Broken Defects**
Appear as thin silver lines or as larger regions

**Label Imbalance**:

- Normal region: 99.77%
- Attached: 0.2%
- Broken: 0.03%

The defects in this dataset occupy a very small proportion relative to the defect-free background. Consequently, when training with the original defect images using the commonly employed loss function, CrossEntropyLoss, the IoU and accuracy performance remain suboptimal.

## Data Augmentation Method

### Method

We applied the RLI technique to the conventional null-text inversion method to slightly edit the defects without significantly degrading the original images.

### Parameter Introduction

- **RLI Parameter**
    - Î± = 0.1
- **Prompt-to-Prompt Parameter**
    - cross = 0.4
    - self = 0.3
    - eq = 2
- **Diffusion Parameter**
    - LOW_RESOURCE = False
    - NUM_DDIM_STEPS = 50
    - GUIDANCE_SCALE = 15

### Prompt

- Source Prompt: "photo of a crack"
- Target Prompt: "photo of a crack with [word]" (Candidate words: scratch, rust, peeling, corrosion, blistering, dent)

### Labeling

| Model         | Trained on                | Attached IoU â†‘ | Attached Acc â†‘ | Broken IoU â†‘ | Broken Acc â†‘ | mIoU  | mAcc  |
|--------------|--------------------------|---------------|---------------|-------------|-------------|-------|-------|
| **Fast-SCNN** | Original dataset | 30.04         | 34.39         | 22.21       | 37.02       | 26.125 | 35.705 |
|              | w/o re-labeling           | 35.89         | 44.42         | 22.25       | **39.79**   | 29.07  | 42.105 |
|              | w/ re-labeling            | **36.94**     | **78.25**     | **23.58**   | 38.8        | **30.26** | **58.525** |
| **MobileNetV3** | Original dataset | 39.62         | 44.95         | 38.11       | **72.22**   | 38.865 | 58.585 |
|              | w/o re-labeling           | 42.65         | 47.27         | 37.72       | 62.55       | 40.185 | 54.91  |
|              | w/ re-labeling            | **53.84**     | **79.72**     | **39.96**   | 56.68       | **46.9**  | **68.2**  |

*Table 1: Comparison before and after re-labeling*

To determine whether re-labeling of the augmented data was necessary, the model was initially trained using the original labels.

While the FastSCNN model showed improvements across all metrics, the MobileNet_v3 model exhibited decreased performance in the broken regions. Consequently, We determine to make re-labeling of the augmented images.

### Result of Augmented Images
<p align="center">
    <img src="./readme_img/aug_defect.png" width=500>
</p>


## Loss Function Selection and Augmented Data Selection

### Issue 1: Loss Function

### Observations

When using CrossEntropyLoss, training did not proceed properly regardless of data augmentation, and performance decreased.

### Solution â€“Â **Introduction of Focal Loss**

### Theory

$$FL(p_t) = -\alpha_t(1-p_t)^\gamma log(p_t)$$

CrossEntropyLoss focuses on the large background regions, resulting in inadequate learning of the small defects. To remedy this, Focal Loss was introduced to reduce the loss contribution from easily detected regions while emphasizing the loss for the hard-to-detect, small defects.

In this dataset, the introduction of Focal Loss is particularly necessary due to the severe label imbalance resulting from the extremely small size of the defects.

### Performance Comparison of Each Loss Function

| Dataset   | Loss Func.                | Attached IoU â†‘ | Attached Acc â†‘ | Broken IoU â†‘ | Broken Acc â†‘ | mIoU  | mAcc  |
|-----------|---------------------------|---------------|---------------|-------------|-------------|-------|-------|
| **Original** | Focal Loss               | **44.34**     | _61.05_       | **22.33**   | _36.31_     | **33.335** | _48.68_ |
|           | Tversky Loss              | 41.29         | 57.77         | 19.25       | 26.29       | 30.27  | 42.03  |
|           | CrossEntropy Loss         | 37.53         | 41.94         | 9.85        | 10.37       | 23.69  | 26.155 |
|           | Dice Loss                 | 37.17         | 52.99         | 7.39        | 7.6         | 22.28  | 30.295 |
|           | Focal + Tversky Loss      | 24.11         | **77.2**      | 21.31       | **42.35**   | 22.71  | **59.775** |
|           | Dice + CrossEntropy Loss  | 25.6          | 27.72         | 12.89       | 14.27       | 19.245 | 20.995 |

*Table 2: Comparison of segmentation performance using different loss functions. Focal Loss achieves the highest mIoU and second position on mAcc.*

### Relation with Augmented Data

| Model         | Trained on                                  | Attached IoU â†‘ | Attached Acc â†‘ | Broken IoU â†‘ | Broken Acc â†‘ | mIoU  | mAcc  |
|--------------|--------------------------------------------|---------------|---------------|-------------|-------------|-------|-------|
| **Fast-SCNN** | FocalLoss w/o aug.                        | 30.04         | 34.39         | 22.21       | 37.02       | 26.125 | 35.705 |
|              | CrossEntropyLoss w/ Peeling aug.          | 32.54         | 34.75         | 12.5        | 13.51       | 22.52  | 24.13  |
|              | **FocalLoss w/ Peeling aug.**             | **36.94**     | **78.25**     | **23.58**   | **38.8**    | **30.26** | **58.525** |
| **MobileNetV3** | FocalLoss w/o aug.                     | 39.62         | 44.95         | 38.11       | 72.22       | 38.865 | 58.585 |
|              | CrossEntropyLoss w/ Peeling aug.          | 39.07         | 41.08         | 34.56       | 39.84       | 36.815 | 40.46  |
|              | **FocalLoss w/ Peeling aug.**             | **53.84**     | **79.72**     | **39.96**   | **56.68**   | **46.9**  | **68.2**  |
| **BiSeNetV2** | FocalLoss w/o aug.                       | 44.33         | 62.75         | 24.29       | **51.58**   | 34.31  | **57.165** |
|              | CrossEntropyLoss w/ Peeling aug.          | 21.72         | 22.79         | 17.72       | 20.39       | 19.72  | 21.59  |
|              | **FocalLoss w/ Peeling aug.**             | **46.24**     | **68.52**     | **24.3**    | 37.18       | **35.27** | 52.85  |

*Table3: Comparison of augmented data using CrossEntropyLoss vs. FocalLoss.*


Comparison of augmented data using CrossEntropyLoss vs. FocalLoss

Using CrossEntropyLoss with augmented defect images led to decreased performance (20.53% on mIoU, 41.86% on mAcc) in most models, with FastSCNN being the only exception. On the other hand, using Focal Loss improved the performance of most models (12.09% on mIoU, 24.25% on mAcc), though the accuracy for broken defects decreased slightly in two models.

This results appears to be due to the augmentation doubling similar images, resulting in the large normal regions being learned more extensively and exacerbating the label imbalance issue. 

### Hyperparameter Tuning

- **gamma**: A parameter that reduces the loss weight for predictions with high confidence, thereby lowering the loss contribution of high-confidence predictions.
- **alpha**: A parameter that assigns class-specific weights, with higher weights allocated to the smaller defects.
- **Experimental Setup**: Alpha was set to [0.1, 0.3, 0.6] for the classes background, attached, and broken, respectively, and gamma was tuned to determine the optimal value.

**[Broken Defect Validation Test Graph]**

<p align="center">
    <img src="./readme_img/broken_iou.png" width=400>
    <img src="./readme_img/broken_acc.png" width=400>
</p>



**[Attached Defect Validation Test Graph]**

<p align="center">
    <img src="./readme_img/attached_iou.png" width=400>
    <img src="./readme_img/attached_acc.png" width=400>
</p>

The above graphs indicate that from the early stages of training, using Focal Loss led to more stable learning compared to CrossEntropyLoss. Moreover, during training, the segmentation performance for broken defectsâ€”as measured by IoU and Accuracyâ€”was higher on the validation set when using Focal Loss.

**[Test Set Evaluation]**

<p align="center">
    <img src="./readme_img/test_set_eval.png" width=700>
</p>

Test set experiments also confirmed that Focal Loss outperformed CrossEntropyLoss. Additionally, as indicated in the table, the highest mIoU and mAcc were achieved when gamma was set to 2; hence, gamma was fixed at 2 for training.

### Issue 2: Augmented Data



### Observations

Not all augmented data contributed to performance improvement. Following the observation, We should find the appropriate dataset among the augmented datasets created by different words to increase the performance of the model.

### **Finding the Best-Performing Augmented Dataset**

|               | Dataset                               | Attached IoU â†‘ | Attached Acc â†‘ | Broken IoU â†‘ | Broken Acc â†‘ | mIoU  | mAcc  |
|--------------|-------------------------------------|---------------|---------------|-------------|-------------|-------|-------|
| **w/o aug.** | Original Dataset      | 30.04         | 34.39         | 22.21       | 37.02       | 26.125 | 35.705 |
| **w/ aug.**  | blistering           | **45.2**      | **73.98**     | _21.42_     | **49.18**   | **33.31**  | **61.58**  |
|              | corrosion            | _28_          | **73.7**      | **23.65**   | **44.91**   | _25.825_   | **59.305** |
|              | dent                 | **46.81**     | **70.06**     | **22.96**   | _37_        | **34.885** | **53.53**  |
|              | peeling              | **36.94**     | **78.25**     | **23.58**   | **38.8**    | **30.26**  | **58.525** |
|              | rust                 | **40.07**     | **51.4**      | **23.34**   | **39.95**   | **31.705** | **45.675** |
|              | scratch              | _27.3_        | **79.21**     | **22.57**   | **40.47**   | _24.935_   | **59.84**  |

*Table4: Comparison of augmented datasets using different defect types.*


Performance improvement by target prompt

- **Step 1**: Exclude datasets in which performance decreased on any metric compared to the original data (i.e., all, blistering, corrosion, scratch).
- **Step 2**: Among the remaining datasets (dent, peeling, rust), comparison of the highest performance (red indicates the best performance and blue the second best) revealed that the peeling-augmented dataset most consistently improved performance across all defect types.
- **Final Decision**: Henceforth, all model experiments will utilize the peeling-augmented dataset.

### Final Training Method Decided



- **Loss Function**:
    - Focal Loss
        - **Alpha values**:
            - Normal: 0.1
            - Attached: 0.3
            - Broken: 0.6
        - **Gamma value**:
            - 2
- **Learning Rate**: 0.001
- **Optimizer**: AdamW
- **Dataset**:
    - The dataset augmented with peeling

## Results

| Model       | Trained on     | Attached IoU | Attached Acc | Broken IoU | Broken Acc | mIoU  | mAcc  |
|------------|---------------|--------------|--------------|------------|------------|-------|-------|
| **GCNet**  | w/ Augmented  | **49.97**    | **67.26**    | **27.58**  | **63.6**   | **38.775** | **65.43**  |
|            | Original      | 41.87        | 53.23        | 26.24      | 59.66      | 34.055  | 56.445  |
| **APCNet** | w/ Augmented  | **48.39**    | **63.59**    | **28.2**   | **61.43**  | **38.295** | **62.51**  |
|            | Original      | 43.39        | 50.07        | 16.42      | 18.1       | 29.905  | 34.085  |
| **PSPNet** | w/ Augmented  | **45.25**    | **64.96**    | **27.56**  | **59.57**  | **36.405** | **62.265**  |
|            | Original      | 37.85        | 45.16        | 27.19      | 56.49      | 32.52  | 50.825  |
| **Fast-SCNN** | w/ Augmented  | **36.94**    | **78.25**    | **23.58**  | **38.80**  | **30.26**  | **58.525**  |
|            | Original      | 30.04        | 34.39        | 22.21      | 37.02      | 26.125  | 35.705  |
| **MobileNetV3** | w/ Augmented  | **51.58**    | **68.45**    | **39.07**  | _71.08_    | **45.325** | **69.765**  |
|            | Original      | 40.51        | 47.49        | 37         | 71.23      | 38.755  | 59.36  |
| **UPerNet** | w/ Augmented  | **54.1**     | **70.51**    | _35.96_    | **73.55**  | **45.03**  | **72.03**  |
|            | Original      | 34.44        | 38.77        | 36.01      | 73.1       | 35.225  | 55.935  |
| **ANN**    | w/ Augmented  | **48.78**    | **67.65**    | **25.53**  | _62.87_    | **37.155** | **65.26**  |
|            | Original      | 42.04        | 55.72        | 25.45      | 63.62      | 33.745  | 59.67  |
| **BiSeNetV2** | w/ Augmented  | **42.12**    | **53.14**    | **26.35**  | _55.56_    | **34.235** | **54.35**  |
|            | Original      | 25.31        | 27.72        | 25.82      | 56.4       | 25.565  | 42.06  |
| **BEiT**   | w/ Augmented  | **34.59**    | **58.28**    | **19.55**  | _26.85_    | **27.07**  | **42.565**  |
|            | Original      | 29           | 41.35        | 18.76      | 29.21      | 23.88   | 35.28   |
| **ViT**    | w/ Augmented  | **33.68**    | **39.68**    | **19.4**   | _30.38_    | **26.54**  | **35.03**  |
|            | Original      | 30.59        | 34.31        | 19         | 31.44      | 24.795  | 32.875  |
| **CCNet**  | w/ Augmented  | **41.63**    | **73.84**    | **27.07**  | _44.25_    | **34.35**  | _59.045_  |
|            | Original      | 37.56        | 70.22        | 25.73      | 71.14      | 31.645  | 70.68  |
| **DANet**  | w/ Augmented  | **50.41**    | **76.18**    | **27.09**  | _42.19_    | **38.75**  | _59.185_  |
|            | Original      | 46.89        | 71.99        | 26.38      | 65.79      | 36.635  | 68.89  |

# Acknowledgement
* Our code has been modified based on the original project of [MMSegmentation](https://github.com/open-mmlab/mmsegmentation) by OpenMMLab
* This work was supported by Institute of Information & communica-
tions Technology Planning & Evaluation (IITP) grant funded by the Ko-
rea government (MSIT) (No.RS-2022-00155915, Artificial Intelligence Con-
vergence Innovation Human Resources Development (Inha University) and
No.2021-0-02068, Artificial Intelligence Innovation Hub and IITP-2024-RS-
2024-00360227, Leading Generative AI Human Resources Development).
